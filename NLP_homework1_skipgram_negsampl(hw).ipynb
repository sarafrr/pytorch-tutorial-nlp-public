{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# General Note\n",
        "In order to guide you through the homework, we put \"...COMPLETE HERE...\" as placeholder for you to complete the homework."
      ],
      "metadata": {
        "id": "o_eszrBYDC7m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yloZQbEP6F2g"
      },
      "source": [
        "# Skip-gram Word2Vec with Negative Sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UkRtF386F2i"
      },
      "source": [
        "\n",
        "## Word2Vec\n",
        "\n",
        "* Here we implement **skip-gram architecture** with **negative sampling**, as it performs better than CBOW and trains faster than negative sampling.\n",
        "\n",
        "* Given a word, it has to predict the surrounding words: it has to learn representations of words that have a similar context."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ],
      "metadata": {
        "id": "rzw1uW710uSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFThS0Hh6F2j"
      },
      "source": [
        "## Get the data\n",
        "\n",
        "Download the data as the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/sarafrr/pytorch-tutorial-nlp-public.git"
      ],
      "metadata": {
        "id": "NIBvm67m0clH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r pytorch-tutorial-nlp-public"
      ],
      "metadata": {
        "id": "RJt26hxO0f5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from the folder containing the data, obtain the list of all the files\n",
        "from glob import glob\n",
        "file_list = glob( \"/content/data/Shakespeare/*.txt\")\n",
        "\n",
        "print(file_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX79dqtl0iYT",
        "outputId": "f97a83e4-40cd-4221-a854-92e60c5b9b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/data/Shakespeare/1513.txt', '/content/data/Shakespeare/1102.txt', '/content/data/Shakespeare/1515-0.txt', '/content/data/Shakespeare/1101.txt', '/content/data/Shakespeare/1510.txt', '/content/data/Shakespeare/1517.txt', '/content/data/Shakespeare/1508-0.txt', '/content/data/Shakespeare/1514-0.txt', '/content/data/Shakespeare/1128.txt', '/content/data/Shakespeare/1519-0.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "for p in file_list:\n",
        "  with open(p, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for l in lines:\n",
        "      text += l"
      ],
      "metadata": {
        "id": "YLTrmvQi4VVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwUVJdA74eFK",
        "outputId": "99dd7a43-ca0a-49e6-d63f-de7b42b55460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCENE.--During the greater part of the Play in Verona; once, in\n",
            "the Fifth Act, at Mantua.\n",
            "\n",
            "THE PROLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRq7JM1B6F2m"
      },
      "source": [
        "# 2. Pre-process text\n",
        "\n",
        "* Convert any punctuation into tokens, e.g. a period is changed to ` <PERIOD> `. (Note: `text8` dataset doesn't contain any periods.)\n",
        "* Remove all words that show up ≤5 times in the dataset to\n",
        "  * reduce issues due to noise in the data\n",
        "  * improve the quality of the vector representations\n",
        "* Return a list of preprocessed words in the text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "    # Convert all text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace punctuation with tokens so we can use them in our model\n",
        "    text = text.replace('.', ' <PERIOD> ')\n",
        "    text = text.replace(',', ' <COMMA> ')\n",
        "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "    text = text.replace(';', ' <SEMICOLON> ')\n",
        "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "    text = text.replace('--', ' <HYPHENS> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
        "    text = text.replace(':', ' <COLON> ')\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove all words with 5 or less occurences\n",
        "    word_counts = Counter(words)\n",
        "    trimmed_words = [word for word in words if word_counts[word] > 5]\n",
        "\n",
        "    return trimmed_words"
      ],
      "metadata": {
        "id": "qM0e4neZmZJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVcjWdLR6F2m",
        "outputId": "e47b355f-5a06-4078-9e73-086622f3ec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCENE.--During the greater part of the Play in Verona; once, in\n",
            "the Fifth Act, at Mantua.\n",
            "\n",
            "THE PROLO\n",
            "['scene', '<PERIOD>', '<HYPHENS>', 'the', 'greater', 'part', 'of', 'the', 'play', 'in', 'verona', '<SEMICOLON>', 'once', '<COMMA>', 'in', 'the', 'fifth', 'act', '<COMMA>', 'at', 'mantua', '<PERIOD>', 'the', 'prologue', '[enter', '<PERIOD>', ']', '<PERIOD>', 'two', '<COMMA>']\n"
          ]
        }
      ],
      "source": [
        "# get vocabulary\n",
        "words = preprocess(text)\n",
        "print(text[:100])\n",
        "print(words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gNXxBRK6F2n",
        "outputId": "6b3b5006-f4bb-44d9-8851-ff67beb94ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total # of words: 291011\n",
            "# of unique words: 3504\n"
          ]
        }
      ],
      "source": [
        "print(\"Total # of words: {}\".format(len(words)))\n",
        "print(\"# of unique words: {}\".format(len(set(words))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckN4p4Sf6F2n"
      },
      "source": [
        "# 3. Create Dictionaries\n",
        "\n",
        "Sorted in descending frequency order (e.g. most frequent word `\"the\"` is assigned as `0`).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    - words: list of words\n",
        "    - return: 2 dictionaries, vocab_to_int, int_to_vocab\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True) # descending freq order\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab"
      ],
      "metadata": {
        "id": "xi_GjCsjm4My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDgO88GV6F2o",
        "outputId": "92c3ead8-491e-4d03-c639-f6b77fe19dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<COMMA>': 0, '<PERIOD>': 1, 'the': 2, 'and': 3, 'i': 4, 'to': 5, 'of': 6, '<SEMICOLON>': 7, 'a': 8, 'you': 9, 'my': 10, 'in': 11, '<QUESTION_MARK>': 12, 'that': 13, 'is': 14, '<EXCLAMATION_MARK>': 15, 'not': 16, 'with': 17, 'for': 18, 'me': 19, 'it': 20, 'be': 21, 'this': 22, 'your': 23, 'his': 24, '<COLON>': 25, 'but': 26, 'will': 27, 'have': 28, 'he': 29, 'as': 30, 'thou': 31, 'so': 32, 'her': 33, 'him': 34, 'what': 35, 'by': 36, 'thy': 37, 'or': 38, 'no': 39, 'if': 40, 'all': 41, 'shall': 42, 'are': 43, 'do': 44, 'thee': 45, 'we': 46, 'king': 47, 'on': 48, 'come': 49, 'now': 50, 'sir': 51, ']': 52, 'at': 53, 'good': 54, 'she': 55, 'from': 56, 'love': 57, 'am': 58, '<HYPHENS>': 59, 'our': 60, 'well': 61, 'how': 62, 'here': 63, 'lord': 64, 'then': 65, 'o': 66, 'they': 67, 'more': 68, 'would': 69, 'man': 70, 'let': 71, 'go': 72, 'an': 73, 'when': 74, 'may': 75, 'was': 76, 'hath': 77, 'which': 78, 'one': 79, 'them': 80, 'than': 81, 'say': 82, 'there': 83, 'their': 84, 'why': 85, 'see': 86, 'make': 87, 'should': 88, 'know': 89, 'like': 90, 'enter': 91, 'such': 92, 'were': 93, 'must': 94, 'project': 95, 'can': 96, 'any': 97, 'these': 98, 'upon': 99, 'us': 100, 'yet': 101, 'master': 102, 'take': 103, 'page': 104, 'did': 105, 'give': 106, 'some': 107, 'out': 108, \"i'll\": 109, 'too': 110, 'where': 111, 'had': 112, 'lady': 113, 'tell': 114, 'never': 115, 'father': 116, 'warwick': 117, 'up': 118, 'who': 119, 'away': 120, 'mine': 121, 'speak': 122, 'romeo': 123, 'heart': 124, 'sweet': 125, 'much': 126, 'doth': 127, 'ford': 128, 'henry': 129, 'queen': 130, 'hear': 131, 'old': 132, 'other': 133, 'ay': 134, 'duke': 135, 'fair': 136, 'nor': 137, 'pray': 138, 'gloucester': 139, \"'tis\": 140, 'most': 141, 'york': 142, 'death': 143, 'god': 144, 'edward': 145, '1': 146, 'night': 147, 'think': 148, 'gutenberg-tm': 149, 'art': 150, 'time': 151, 'lear': 152, 'look': 153, 'don': 154, 'house': 155, 'before': 156, 'eyes': 157, 'life': 158, 'hand': 159, 'cannot': 160, 'therefore': 161, 'true': 162, 'scene': 163, 'work': 164, 'very': 165, 'petruchio': 166, 'men': 167, 'day': 168, 'first': 169, 'made': 170, 'mrs': 171, 'claudio': 172, 'benedick': 173, 'two': 174, 'thus': 175, 'comes': 176, 'mistress': 177, 'gutenberg': 178, 'berowne': 179, 'been': 180, 'leave': 181, 'both': 182, 'name': 183, 'falstaff': 184, 'nay': 185, 'son': 186, 'till': 187, 'fool': 188, 'great': 189, 'john': 190, 'head': 191, 'kent': 192, 'down': 193, 'again': 194, 'world': 195, 'juliet': 196, '[enter': 197, '<LEFT_PAREN>': 198, '<RIGHT_PAREN>': 199, 'stand': 200, 'into': 201, 'own': 202, 'daughter': 203, 'i’ll': 204, 'myself': 205, 'call': 206, 'about': 207, 'nothing': 208, \"'\": 209, 'hast': 210, 'unto': 211, 'word': 212, 'being': 213, 'wife': 214, 'prince': 215, 'leonato': 216, 'works': 217, 'beatrice': 218, 'fear': 219, 'poor': 220, 'way': 221, 'full': 222, 'part': 223, 'better': 224, 'stay': 225, '[exit': 226, 'nurse': 227, 'long': 228, 'pedro': 229, 'use': 230, 'though': 231, 'marry': 232, 'portia': 233, 'many': 234, 'electronic': 235, 'three': 236, '[exeunt': 237, 'dead': 238, 'grace': 239, 'margaret': 240, 'could': 241, 'ever': 242, 'madam': 243, 'tranio': 244, 'keep': 245, 'hold': 246, 'gone': 247, '_]': 248, 'blood': 249, 'suffolk': 250, 'capulet': 251, 'antonio': 252, 'set': 253, 'young': 254, 'find': 255, 'clifford': 256, 'heaven': 257, 'words': 258, 'bear': 259, 'die': 260, 'even': 261, 'face': 262, 'friar': 263, 'princess': 264, 'brother': 265, 'whose': 266, 'quickly': 267, 'thine': 268, 'still': 269, 'against': 270, 'only': 271, 'eye': 272, 'boy': 273, 'live': 274, 'done': 275, 'forth': 276, 'right': 277, 'another': 278, 'every': 279, 'friend': 280, 'france': 281, 'bassanio': 282, '<QUOTATION_MARK>': 283, 'armado': 284, 'without': 285, 'bid': 286, 'gentleman': 287, 'follow': 288, 'little': 289, 'lucentio': 290, 'hortensio': 291, 'glou': 292, 'none': 293, 'costard': 294, 'hence': 295, 'show': 296, 'off': 297, 'rest': 298, 'within': 299, 'lords': 300, 'best': 301, 'faith': 302, 'ere': 303, 'hero': 304, 'dear': 305, 'mind': 306, 'else': 307, 'katherina': 308, 'put': 309, 'place': 310, 'please': 311, 'husband': 312, 'tongue': 313, 'letter': 314, 'evans': 315, 'get': 316, 'indeed': 317, 'answer': 318, 'bring': 319, 'himself': 320, 'terms': 321, 'help': 322, 'hope': 323, 'shallow': 324, 'shylock': 325, 'peace': 326, 'those': 327, 'soul': 328, 'richard': 329, 'slender': 330, 'baptista': 331, 'wilt': 332, 'came': 333, 'light': 334, 'wit': 335, 'copyright': 336, 'dost': 337, 'woman': 338, \"th'\": 339, 'thousand': 340, 'exeunt': 341, 'meet': 342, 'lysander': 343, 'while': 344, 'rosaline': 345, 'boyet': 346, 'signior': 347, 'things': 348, 'demetrius': 349, 'gentle': 350, '’tis': 351, 'moth': 352, 'hermia': 353, 'edg': 354, 'once': 355, 'shalt': 356, 'heard': 357, 'through': 358, 'foundation': 359, 'cade': 360, 'whom': 361, 'makes': 362, 'farewell': 363, 'under': 364, 'honour': 365, 'grumio': 366, 'back': 367, 'friends': 368, 'clarence': 369, 'crown': 370, 'play': 371, 'since': 372, 'thank': 373, 'e': 374, 'means': 375, 'state': 376, 'gremio': 377, 'hands': 378, 'tears': 379, 'end': 380, 'welcome': 381, 'might': 382, 'news': 383, 'law': 384, 'said': 385, 'thought': 386, 'somerset': 387, 'host': 388, 'servant': 389, 'enough': 390, 'swear': 391, 'shame': 392, 'pardon': 393, 'after': 394, 'thing': 395, 'exit': 396, 'turn': 397, 'seek': 398, 'rather': 399, 'ah': 400, 'same': 401, 'anne': 402, 'villain': 403, 'noble': 404, 'honest': 405, 'mean': 406, 'child': 407, 'mercutio': 408, 'matter': 409, 'hither': 410, 'bianca': 411, 'sword': 412, 'says': 413, 'lorenzo': 414, 'launcelet': 415, 'break': 416, 'lie': 417, 'watch': 418, 'states': 419, 'benvolio': 420, 'bed': 421, 'fellow': 422, 'messenger': 423, 'send': 424, 'reason': 425, 'caius': 426, 'edm': 427, 'montague': 428, 'new': 429, 'cause': 430, 'fortune': 431, 'sure': 432, 'told': 433, 'prove': 434, 'second': 435, 'agreement': 436, 'talk': 437, 'fire': 438, 'charge': 439, '[aside]': 440, 'home': 441, 'wrong': 442, 'simple': 443, 'gratiano': 444, 'reg': 445, 'hour': 446, 'helena': 447, 'run': 448, 'because': 449, 'company': 450, 'william': 451, 'near': 452, 'read': 453, 'wear': 454, 'bottom': 455, 'copies': 456, 'act': 457, 'tybalt': 458, 'cousin': 459, 'half': 460, 'truth': 461, 'money': 462, 'biondello': 463, 'unless': 464, 'far': 465, 'foul': 466, 'kind': 467, 'kill': 468, 'body': 469, 'donations': 470, 'mad': 471, 'fly': 472, '[to': 473, \"we'll\": 474, 'between': 475, 'fight': 476, 'seen': 477, 'married': 478, 'yourself': 479, 'spirit': 480, 'has': 481, 'court': 482, 'wise': 483, 'last': 484, '-': 485, '’': 486, 'theseus': 487, 'days': 488, 'wish': 489, 'joy': 490, 'corn': 491, 'jew': 492, 'maid': 493, 'sleep': 494, 'merry': 495, 'moon': 496, 'false': 497, 'nerissa': 498, 'doctor': 499, 'dumaine': 500, 'kate': 501, 'lay': 502, 'saw': 503, 'alone': 504, 'ill': 505, 'sight': 506, 'sit': 507, 'desire': 508, 'sound': 509, 'oath': 510, 'sun': 511, 'earth': 512, 'ye': 513, 'others': 514, 'peter': 515, 'soldiers': 516, 'holofernes': 517, 'sirrah': 518, 'fall': 519, \"that's\": 520, 'times': 521, 'power': 522, 'nature': 523, 'twenty': 524, 'draw': 525, 'yours': 526, 'paris': 527, 'left': 528, 'wind': 529, 'music': 530, 'knave': 531, 'sister': 532, 'buckingham': 533, 'jessica': 534, 'longaville': 535, 'pyramus': 536, 'dogberry': 537, 'warrant': 538, \"there's\": 539, 'over': 540, 'fie': 541, '—': 542, 'alb': 543, 'grief': 544, 'mother': 545, 'gentlemen': 546, 'ready': 547, 'found': 548, 'return': 549, 'methinks': 550, 'distributed': 551, 'service': 552, 'license': 553, 'literary': 554, 'archive': 555, 'serve': 556, 'yes': 557, 'strange': 558, 'gave': 559, 'itself': 560, 'yea': 561, 'brook': 562, 'flesh': 563, \"let's\": 564, 'lost': 565, 'ask': 566, 'free': 567, 'horse': 568, 'united': 569, 'cardinal': 570, 'neither': 571, 'happy': 572, 'kiss': 573, 'pity': 574, 'need': 575, 'jest': 576, 'trust': 577, 'hang': 578, 'rich': 579, 'ii': 580, 'lies': 581, 'marriage': 582, 'less': 583, 'loves': 584, 'plain': 585, \"i'\": 586, 'ten': 587, 'proud': 588, 'together': 589, 'ebook': 590, 'gon': 591, 'alas': 592, 'lead': 593, 'cold': 594, 'care': 595, 'ear': 596, 'looks': 597, 'purpose': 598, 'lose': 599, 'coming': 600, 'edmund': 601, 'cut': 602, 'foot': 603, 'gold': 604, 'bound': 605, 'sent': 606, 'person': 607, '2': 608, 'next': 609, 'fault': 610, 'does': 611, 'quince': 612, 'puck': 613, 'canst': 614, 'hard': 615, 'years': 616, 'small': 617, 'late': 618, 'sport': 619, 'youth': 620, 'mercy': 621, 'arms': 622, 'present': 623, '3': 624, 'permission': 625, '[_exit': 626, 'copy': 627, 'borachio': 628, \"o'\": 629, 'ho': 630, 'lives': 631, 'beauty': 632, 'age': 633, 'choose': 634, 'beseech': 635, 'ha': 636, 'saint': 637, 'sake': 638, 'cry': 639, 'ring': 640, 'haste': 641, 'majesty': 642, 'praise': 643, 'dare': 644, 'either': 645, \"he's\": 646, 'room': 647, 'stands': 648, 'content': 649, 'breath': 650, 'white': 651, 'field': 652, 'slain': 653, 'knows': 654, 'london': 655, 'trademark': 656, 'known': 657, 'straight': 658, 'believe': 659, 'knight': 660, 'high': 661, 'truly': 662, 'distribution': 663, 'england': 664, 'fenton': 665, 'ground': 666, 'pleasure': 667, 'soon': 668, 'mark': 669, 'agree': 670, 'took': 671, 'save': 672, 'patience': 673, \"what's\": 674, 'access': 675, 'form': 676, \"father's\": 677, 'each': 678, 'devil': 679, 'thisbe': 680, 'worship': 681, 'brought': 682, 'lion': 683, 'laws': 684, 'bond': 685, 'oberon': 686, 'wall': 687, 'goes': 688, 'humour': 689, 'change': 690, 'dream': 691, 'above': 692, 'lips': 693, 'deny': 694, 'holy': 695, 'fee': 696, 'provided': 697, 'given': 698, 'salisbury': 699, 'pass': 700, 'side': 701, 'counsel': 702, \"ne'er\": 703, 'sorrow': 704, 'got': 705, 'earl': 706, 'traitor': 707, 'people': 708, 'duchess': 709, 'ebooks': 710, 'refund': 711, 'paragraph': 712, 'f': 713, 'vincentio': 714, 'dog': 715, 'black': 716, 'sad': 717, \"here's\": 718, 'sea': 719, 'worse': 720, 'write': 721, 'born': 722, 'doubt': 723, 'further': 724, 'sovereign': 725, 'lewis': 726, 'yield': 727, 'heavy': 728, 'air': 729, 'suit': 730, \"o'er\": 731, 'ladies': 732, 'sing': 733, 'fit': 734, 'duty': 735, 'salarino': 736, 'strike': 737, 'servants': 738, 'loving': 739, 'sworn': 740, 'gives': 741, 'business': 742, 'entreat': 743, '[aside': 744, 'thyself': 745, 'confess': 746, 'thanks': 747, 'justice': 748, 'wonder': 749, 'presently': 750, 'oxford': 751, 'george': 752, 'venice': 753, '[_exeunt': 754, 'pistol': 755, 'gent': 756, 'hate': 757, 'hell': 758, 'case': 759, 'chamber': 760, 'note': 761, 'comfort': 762, 'iii': 763, 'spoke': 764, 'measure': 765, 'heir': 766, 'appear': 767, 'knew': 768, 'gracious': 769, 'something': 770, 'fare': 771, 'paid': 772, 'information': 773, 'fairy': 774, 'titania': 775, 'masters': 776, 'remember': 777, 'bloody': 778, 'withal': 779, 'glad': 780, 'seem': 781, 'fast': 782, 'course': 783, 'hot': 784, 'hearts': 785, 'hundred': 786, 'adieu': 787, 'thoughts': 788, 'worth': 789, 'office': 790, 'hugh': 791, 'paper': 792, 'grey': 793, 'base': 794, 'humphrey': 795, 'pretty': 796, 'uncle': 797, 'four': 798, 'want': 799, 'brave': 800, 'study': 801, 'including': 802, 'osw': 803, 'ears': 804, 'walk': 805, 'morning': 806, 'sick': 807, 'weep': 808, 'voice': 809, 'dull': 810, 'sin': 811, 'alack': 812, 'virtue': 813, 'third': 814, 'revenge': 815, 'parts': 816, 'worthy': 817, 'certain': 818, 'used': 819, 'command': 820, 'provide': 821, 'de': 822, 'carry': 823, 'grow': 824, 'having': 825, 'hide': 826, 'letters': 827, 'often': 828, 'already': 829, 'five': 830, 'vile': 831, \"you'll\": 832, 'open': 833, 'bold': 834, 'met': 835, 'following': 836, 'needs': 837, 'country': 838, 'ducats': 839, 'war': 840, 'until': 841, 'royal': 842, 'fashion': 843, 'eat': 844, 'padua': 845, 'gods': 846, 'nathaniel': 847, 'balthasar': 848, 'grave': 849, 'pay': 850, 'anything': 851, \"she's\": 852, 'teach': 853, 'question': 854, 'woo': 855, 'book': 856, 'count': 857, 'tender': 858, 'tale': 859, 'fetch': 860, 'wherefore': 861, 'door': 862, 'arm': 863, 'didst': 864, 'troth': 865, 'shakespeare': 866, '”': 867, 'what’s': 868, 's': 869, 'rugby': 870, 'quarrel': 871, 'hadst': 872, 'begin': 873, 'hours': 874, 'short': 875, 'widow': 876, 'dance': 877, 'lest': 878, 'prepare': 879, 'pale': 880, 'speaks': 881, 'french': 882, 'hair': 883, 'bless': 884, 'fiend': 885, 'flourish': 886, 'received': 887, 'pedant': 888, 'fairies': 889, 'rage': 890, 'writ': 891, 'daughters': 892, \"'twas\": 893, 'iv': 894, 'woe': 895, 'wits': 896, 'shape': 897, 'title': 898, 'almost': 899, 'dinner': 900, 'drink': 901, 'understand': 902, 'associated': 903, 'katharine': 904, 'bardolph': 905, 'feel': 906, '[they': 907, 'consent': 908, \"where's\": 909, 'oft': 910, 'sometime': 911, 'drum': 912, 'past': 913, 'fine': 914, 'enemy': 915, 'toward': 916, 'maria': 917, 'church': 918, 'beard': 919, 'point': 920, 'just': 921, 'become': 922, 'sly': 923, 'www': 924, 'public': 925, 'among': 926, 'along': 927, 'close': 928, 'wood': 929, 'favour': 930, 'soft': 931, 'hit': 932, 'behold': 933, 'tailor': 934, 'excellent': 935, 'longer': 936, 'bears': 937, 'affection': 938, 'wouldst': 939, 'jack': 940, 'fell': 941, 'palace': 942, 'quick': 943, 'forsooth': 944, 'march': 945, 'land': 946, 'dick': 947, 'that’s': 948, 'windsor': 949, 'horns': 950, 'cor': 951, 'ursula': 952, 'women': 953, 'attendants': 954, 'morrow': 955, 'forsworn': 956, 'blind': 957, 'dark': 958, 'calls': 959, 'judgment': 960, 'storm': 961, 'town': 962, 'forward': 963, 'green': 964, 'water': 965, 'speed': 966, 'low': 967, 'despite': 968, 'readable': 969, 'gar': 970, 'regan': 971, 'conrade': 972, 'blow': 973, 'fools': 974, 'scorn': 975, 'fled': 976, 'brief': 977, 'strength': 978, 'to-night': 979, 'behind': 980, \"man's\": 981, 'hark': 982, 'heavens': 983, 'receive': 984, 'promise': 985, 'issue': 986, 'complete': 987, 'win': 988, 'protector': 989, 'judge': 990, 're-enter': 991, 'volunteers': 992, 'u': 993, 'distribute': 994, 'tax': 995, 'curtis': 996, 'cordelia': 997, 'ancient': 998, 'shows': 999, 'beat': 1000, 'common': 1001, 'deep': 1002, 'learn': 1003, 'vow': 1004, 'forget': 1005, 'match': 1006, 'forbid': 1007, 'virtuous': 1008, 'presence': 1009, 'chance': 1010, 'passion': 1011, 'won': 1012, 'to-morrow': 1013, 'below': 1014, 'least': 1015, 'force': 1016, 'etext': 1017, 'northumberland': 1018, 'gobbo': 1019, 'father’s': 1020, 'tonight': 1021, 'distributing': 1022, 'section': 1023, 'jaquenetta': 1024, 'ass': 1025, 'lovers': 1026, 'valiant': 1027, 'slave': 1028, 'sense': 1029, 'golden': 1030, 'laugh': 1031, 'breast': 1032, 'strong': 1033, 'knock': 1034, 'speech': 1035, 'worst': 1036, 'neighbour': 1037, 'pluck': 1038, 'general': 1039, 'treason': 1040, 'city': 1041, 'mouth': 1042, 'spirits': 1043, 'post': 1044, 'liege': 1045, \"henry's\": 1046, 'lancaster': 1047, 'colours': 1048, 'battle': 1049, \"england's\": 1050, 'prithee': 1051, 'freely': 1052, 'witness': 1053, 'tomorrow': 1054, 'robin': 1055, 'verges': 1056, 'approach': 1057, 'aside': 1058, 'went': 1059, 'number': 1060, 'written': 1061, 'herself': 1062, 'christian': 1063, 'broke': 1064, 'its': 1065, 'vain': 1066, 'anon': 1067, 'silver': 1068, 'beg': 1069, 'search': 1070, 'subject': 1071, 'cross': 1072, 'exeter': 1073, 'charges': 1074, 'sons': 1075, 'park': 1076, 'train': 1077, 'there’s': 1078, 'owner': 1079, 'medium': 1080, 'hippolyta': 1081, 'fearful': 1082, 'attend': 1083, 'gown': 1084, 'pain': 1085, 'wert': 1086, 'choice': 1087, 'wisdom': 1088, 'legs': 1089, 'v': 1090, 'touch': 1091, 'appears': 1092, 'whole': 1093, 'offer': 1094, \"he'll\": 1095, 'trumpet': 1096, 'sort': 1097, 'melancholy': 1098, 'version': 1099, 'machine': 1100, 'gates': 1101, 'themselves': 1102, 'we’ll': 1103, 'athens': 1104, 'edgar': 1105, 'gregory': 1106, 'foe': 1107, 'street': 1108, 'pride': 1109, 'learned': 1110, 'food': 1111, 'thither': 1112, 'laid': 1113, 'meaning': 1114, 'web': 1115, 'wealth': 1116, 'endure': 1117, 'foolish': 1118, 'cunning': 1119, '[re-enter': 1120, 'basket': 1121, 'cheer': 1122, 'stop': 1123, 'meat': 1124, 'commend': 1125, 'bad': 1126, 'ways': 1127, \"god's\": 1128, 'cost': 1129, 'hastings': 1130, 'commercial': 1131, 'staff': 1132, 'swore': 1133, 'highness': 1134, 'crowns': 1135, 'whiles': 1136, 'using': 1137, 'solanio': 1138, 'i’': 1139, 'she’s': 1140, 'comply': 1141, '4': 1142, 'nym': 1143, 'move': 1144, 'stir': 1145, 'heads': 1146, 'several': 1147, 'noise': 1148, 'spite': 1149, 'enemies': 1150, 'throw': 1151, 'depart': 1152, 'rough': 1153, \"love's\": 1154, 'honourable': 1155, 'bride': 1156, 'feast': 1157, 'awhile': 1158, 'wast': 1159, 'cupid': 1160, 'angry': 1161, 'bosom': 1162, 'grant': 1163, 'fain': 1164, 'courtesy': 1165, 'buy': 1166, 'mortal': 1167, 'falls': 1168, 'obey': 1169, 'offence': 1170, 'wild': 1171, 'valour': 1172, 'grows': 1173, 'library': 1174, 'includes': 1175, 'realm': 1176, 'whether': 1177, \"gloucester's\": 1178, \"king's\": 1179, 'gift': 1180, 'fat': 1181, 'clerk': 1182, 'replacement': 1183, 'limited': 1184, 'priest': 1185, 'patient': 1186, 'able': 1187, 'hurt': 1188, 'blows': 1189, 'window': 1190, 'nine': 1191, 'poison': 1192, 'lovely': 1193, 'whither': 1194, 'year': 1195, 'brow': 1196, 'children': 1197, 'yonder': 1198, 'seems': 1199, 'tree': 1200, 'cease': 1201, 'tomb': 1202, 'cheeks': 1203, 'challenge': 1204, 'gross': 1205, 'double': 1206, 'taken': 1207, 'beast': 1208, 'musician': 1209, 'lend': 1210, 'tarry': 1211, 'wales': 1212, 'stafford': 1213, 'claim': 1214, 'conscience': 1215, 'kingdom': 1216, 'oaths': 1217, 'lands': 1218, 'monsieur': 1219, 'protected': 1220, 'simpcox': 1221, 'tom': 1222, 'curst': 1223, 'pompey': 1224, 'goneril': 1225, 'sampson': 1226, 'bite': 1227, 'thrice': 1228, 'towards': 1229, 'stars': 1230, 'county': 1231, 'cried': 1232, 'flower': 1233, 'excuse': 1234, 'rude': 1235, 'phrase': 1236, 'fees': 1237, 'horses': 1238, 'birth': 1239, 'sigh': 1240, 'tear': 1241, 'fortunes': 1242, 'dry': 1243, 'assure': 1244, 'goose': 1245, 'devise': 1246, 'pains': 1247, 'sorry': 1248, 'fury': 1249, 'loss': 1250, 'living': 1251, \"'gainst\": 1252, 'curse': 1253, 'deed': 1254, 'manner': 1255, 'hearing': 1256, 'notice': 1257, 'personal': 1258, 'download': 1259, 'english': 1260, 'red': 1261, 'whilst': 1262, 'castle': 1263, 'check': 1264, 'hercules': 1265, 'keeper': 1266, \"edward's\": 1267, 'hector': 1268, 'deserve': 1269, 'pound': 1270, 'here’s': 1271, 'compliance': 1272, 'damages': 1273, 'weak': 1274, 'early': 1275, 'clouds': 1276, 'view': 1277, 'bright': 1278, 'dies': 1279, 'writing': 1280, 'supper': 1281, 'bitter': 1282, 'bearing': 1283, 'wings': 1284, 'heels': 1285, 'wherein': 1286, 'burn': 1287, \"men's\": 1288, 'round': 1289, 'dares': 1290, 'respect': 1291, 'steal': 1292, 'garden': 1293, 'sudden': 1294, 'request': 1295, 'forgot': 1296, 'turns': 1297, 'wench': 1298, 'month': 1299, 'occasion': 1300, 'forbear': 1301, 'slew': 1302, 'order': 1303, 'scarce': 1304, 'blame': 1305, 'dangerous': 1306, 'report': 1307, 'quite': 1308, 'loose': 1309, 'intend': 1310, 'died': 1311, 'editions': 1312, 'lieutenant': 1313, 'university': 1314, 'army': 1315, 'impossible': 1316, 'intent': 1317, 'harm': 1318, 'rain': 1319, 'appointed': 1320, 'burgundy': 1321, 'mighty': 1322, 'always': 1323, 'faults': 1324, 'support': 1325, 'silence': 1326, 'vouchsafe': 1327, 'sign': 1328, 'guard': 1329, 'posted': 1330, 'visit': 1331, 'desires': 1332, 'located': 1333, 'org': 1334, 'additional': 1335, 'countenance': 1336, 'cornwall': 1337, 'leonato’s': 1338, 'greater': 1339, 'weapons': 1340, 'quiet': 1341, 'sighs': 1342, 'secret': 1343, 'bow': 1344, 'prison': 1345, \"lady's\": 1346, 'girl': 1347, 'shake': 1348, 'lover': 1349, 'going': 1350, 'ourselves': 1351, 'hid': 1352, 'murder': 1353, 'kings': 1354, 'meant': 1355, 'goodly': 1356, 'warm': 1357, 'smile': 1358, 'sum': 1359, 'alive': 1360, 'wives': 1361, 'heavenly': 1362, 'tower': 1363, 'wake': 1364, 'trouble': 1365, 'forgive': 1366, 'seal': 1367, 'rutland': 1368, '<<this': 1369, '1990-1993': 1370, 'inc': 1371, 'carnegie': 1372, 'mellon': 1373, 'commercially': 1374, 'prohibited': 1375, 'membership': 1376, '>>': 1377, 'mock': 1378, 'takes': 1379, 'stood': 1380, 'led': 1381, 'whereof': 1382, 'deer': 1383, 'witch': 1384, 'kindness': 1385, 'yourselves': 1386, 'tubal': 1387, 'mirth': 1388, 'purse': 1389, 'apparel': 1390, 'anyone': 1391, 'seven': 1392, 'c': 1393, 'also': 1394, '*': 1395, 'contact': 1396, 'la': 1397, 'moonshine': 1398, 'katherine': 1399, 'mantua': 1400, 'list': 1401, 'whence': 1402, \"lov'd\": 1403, 'making': 1404, 'precious': 1405, 'saying': 1406, 'delight': 1407, 'asleep': 1408, 'finger': 1409, \"is't\": 1410, 'breathe': 1411, 'raise': 1412, 'smell': 1413, 'jove': 1414, 'although': 1415, 'books': 1416, 'fail': 1417, 'reign': 1418, 'deal': 1419, 'remain': 1420, 'wide': 1421, 'argument': 1422, 'gentlewoman': 1423, 'protest': 1424, 'gate': 1425, 'wanton': 1426, 'plague': 1427, \"kill'd\": 1428, 'modesty': 1429, 'dreadful': 1430, 'spring': 1431, 'guilty': 1432, \"who's\": 1433, 'labour': 1434, 'danger': 1435, 'bona': 1436, 'alarum': 1437, 'holds': 1438, 'spend': 1439, 'mild': 1440, 'few': 1441, 'offend': 1442, 'soldier': 1443, 'man’s': 1444, 'lov’d': 1445, 'let’s': 1446, 'bastard': 1447, 'requirements': 1448, 'hume': 1449, 'garter': 1450, 'civil': 1451, 'foes': 1452, 'piece': 1453, 'drawn': 1454, 'sentence': 1455, 'cast': 1456, 'instant': 1457, 'to-day': 1458, 'liberty': 1459, 'names': 1460, 'shut': 1461, 'kept': 1462, 'lamb': 1463, 'spoken': 1464, 'taste': 1465, 'quoth': 1466, \"'a\": 1467, 'wretch': 1468, 'summer': 1469, 'date': 1470, 'fellows': 1471, 'blessed': 1472, 'contrary': 1473, \"call'd\": 1474, 'exchange': 1475, 'thrive': 1476, 'cell': 1477, 'ours': 1478, 'flowers': 1479, 'special': 1480, 'aught': 1481, 'keeps': 1482, 'pure': 1483, 'suffer': 1484, 'knife': 1485, 'catch': 1486, 'beaten': 1487, 'apt': 1488, 'owe': 1489, 'banished': 1490, 'tune': 1491, 'herald': 1492, 'wed': 1493, 'remedy': 1494, 'victory': 1495, 'pleasant': 1496, 'try': 1497, 'clothes': 1498, 'seeing': 1499, 'seest': 1500, 'embrace': 1501, 'plantagenet': 1502, 'belike': 1503, 'kneel': 1504, 'lawful': 1505, 'twice': 1506, 'wont': 1507, 'evil': 1508, 'except': 1509, 'perceive': 1510, 'opinion': 1511, 'defend': 1512, 'lordship': 1513, 'thief': 1514, 'o’er': 1515, 'besides': 1516, 'fancy': 1517, 'creating': 1518, 'status': 1519, 'royalty': 1520, 'iden': 1521, 'egeus': 1522, 'nuncle': 1523, 'verona': 1524, 'prologue': 1525, 'neck': 1526, 'cruel': 1527, 'frown': 1528, 'forfeit': 1529, 'fresh': 1530, \"romeo's\": 1531, 'proof': 1532, 'health': 1533, 'desperate': 1534, 'souls': 1535, 'brain': 1536, 'called': 1537, 'idle': 1538, 'sail': 1539, 'cheek': 1540, 'kinsman': 1541, 'perforce': 1542, 'fairest': 1543, 'drunk': 1544, 'bird': 1545, 'prisoner': 1546, 'stones': 1547, 'sometimes': 1548, 'chide': 1549, 'slow': 1550, 'sharp': 1551, 'bones': 1552, \"they'll\": 1553, 'rogue': 1554, 'sounds': 1555, 'deeds': 1556, \"banish'd\": 1557, \"world's\": 1558, 'becomes': 1559, 'awake': 1560, 'jealous': 1561, 'mayor': 1562, 'parliament': 1563, 'thinks': 1564, 'followers': 1565, \"woman's\": 1566, 'cap': 1567, 'knee': 1568, 'beggar': 1569, 'bush': 1570, 'surely': 1571, 'monstrous': 1572, 'due': 1573, 'hat': 1574, 'possible': 1575, 'start': 1576, 'defect': 1577, 'proceed': 1578, 'print': 1579, 'copying': 1580, 'mission': 1581, '8': 1582, 'b': 1583, 'collection': 1584, 'individual': 1585, 'displaying': 1586, 'format': 1587, 'holder': 1588, 'providing': 1589, 'site': 1590, 'liability': 1591, 'particular': 1592, 'commons': 1593, \"l'envoy\": 1594, 'dat': 1595, 'snout': 1596, 'fatal': 1597, 'thrust': 1598, 'coward': 1599, 'join': 1600, 'steel': 1601, 'fiery': 1602, 'parted': 1603, 'abroad': 1604, 'leaves': 1605, 'coz': 1606, 'tut': 1607, 'broken': 1608, 'niece': 1609, 'cover': 1610, 'six': 1611, 'sore': 1612, 'sits': 1613, 'nose': 1614, 'boys': 1615, 'follows': 1616, 'satisfied': 1617, 'arise': 1618, 'rose': 1619, 'lawrence': 1620, 'action': 1621, 'salt': 1622, 'flies': 1623, 'faint': 1624, 'runs': 1625, 'large': 1626, 'begins': 1627, 'motion': 1628, 'amen': 1629, 'doom': 1630, 'murderer': 1631, 'shed': 1632, 'tedious': 1633, 'brings': 1634, 'undone': 1635, 'honesty': 1636, 'banishment': 1637, 'doing': 1638, 'heed': 1639, 'learning': 1640, 'bark': 1641, 'sees': 1642, 'monument': 1643, 'leisure': 1644, 'borne': 1645, 'heat': 1646, 'tread': 1647, 'deliver': 1648, 'feet': 1649, 'norfolk': 1650, 'mortimer': 1651, 'durst': 1652, 'months': 1653, 'trumpets': 1654, 'tells': 1655, 'shouldst': 1656, 'albans': 1657, 'swain': 1658, 'sheep': 1659, 'shoot': 1660, 'easy': 1661, 'ride': 1662, 'rule': 1663, 'credit': 1664, 'accept': 1665, 'assurance': 1666, 'suspect': 1667, 'suddenly': 1668, 'fox': 1669, 'knights': 1670, 'belmont': 1671, 'lack': 1672, '’twere': 1673, 'proper': 1674, 'outside': 1675, 'ne’er': 1676, 'contain': 1677, 'cuckoo': 1678, 'future': 1679, 'domain': 1680, '5': 1681, 'official': 1682, 'warranties': 1683, 'michael': 1684, 'bolingbroke': 1685, \"humphrey's\": 1686, \"'t\": 1687, 'rascal': 1688, 'parson': 1689, 'bully': 1690, \"ford's\": 1691, 'stocks': 1692, 'flute': 1693, 'athenian': 1694, 'dover': 1695, 'fifth': 1696, 'remove': 1697, 'fray': 1698, 'bred': 1699, 'winds': 1700, 'envious': 1701, 'sadness': 1702, 'add': 1703, 'hers': 1704, 'odds': 1705, 'younger': 1706, 'according': 1707, 'perhaps': 1708, 'beauteous': 1709, 'sisters': 1710, 'twelve': 1711, 'wait': 1712, 'empty': 1713, 'dreams': 1714, 'manners': 1715, 'knaves': 1716, 'elder': 1717, 'held': 1718, 'vows': 1719, 'anger': 1720, 'henceforth': 1721, 'hateful': 1722, 'mayst': 1723, 'fond': 1724, 'song': 1725, 'single': 1726, 'spent': 1727, \"say'st\": 1728, 'shortly': 1729, 'gallant': 1730, \"to't\": 1731, 'throne': 1732, 'blessing': 1733, 'weeps': 1734, 'sack': 1735, 'thursday': 1736, 'bids': 1737, 'weary': 1738, 'suspicion': 1739, 'demand': 1740, 'stanley': 1741, 'killed': 1742, 'seat': 1743, 'favours': 1744, 'princely': 1745, 'enjoy': 1746, 'creep': 1747, 'innocent': 1748, 'abide': 1749, 'cur': 1750, 'methought': 1751, 'feed': 1752, 'knowing': 1753, 'created': 1754, 'tempest': 1755, 'image': 1756, 'obtain': 1757, 'humble': 1758, 'discourse': 1759, 'horn': 1760, 'watchman': 1761, 'charity': 1762, 'top': 1763, 'reverence': 1764, 'god’s': 1765, 'villainy': 1766, 'jealousy': 1767, 'party': 1768, 'donate': 1769, 'efforts': 1770, 'equipment': 1771, 'breach': 1772, 'whitmore': 1773, 'philostrate': 1774, 'albany': 1775, \"'s\": 1776, 'prince’s': 1777, 'fought': 1778, 'subjects': 1779, 'streets': 1780, 'dew': 1781, 'encounter': 1782, 'merit': 1783, 'despair': 1784, 'brows': 1785, 'passing': 1786, 'wine': 1787, 'painted': 1788, 'blush': 1789, 'whip': 1790, 'north': 1791, 'thence': 1792, '&c': 1793, 'worn': 1794, 'jewel': 1795, 'meeting': 1796, 'effect': 1797, '[he': 1798, 'wound': 1799, 'birds': 1800, 'angel': 1801, 'glorious': 1802, 'walls': 1803, 'maiden': 1804, 'weeds': 1805, 'woes': 1806, 'captain': 1807, 'numbers': 1808, 'behaviour': 1809, 'swift': 1810, 'triumph': 1811, 'courage': 1812, 'behalf': 1813, 'wretched': 1814, 'deadly': 1815, 'cries': 1816, 'bought': 1817, \"turn'd\": 1818, 'rise': 1819, 'lark': 1820, \"'twere\": 1821, 'wicked': 1822, 'twain': 1823, 'prevent': 1824, 'dagger': 1825, 'spare': 1826, 'loud': 1827, 'creature': 1828, 'bodies': 1829, 'sixth': 1830, 'rivers': 1831, 'main': 1832, 'chair': 1833, 'pursue': 1834, 'prize': 1835, 'shadow': 1836, 'harmless': 1837, 'flight': 1838, \"receiv'd\": 1839, 'secure': 1840, 'dread': 1841, \"husband's\": 1842, \"highness'\": 1843, 'brothers': 1844, 'govern': 1845, 'dowry': 1846, 'constant': 1847, 'dame': 1848, 'befall': 1849, 'colour': 1850, 'powers': 1851, 'modest': 1852, 'officer': 1853, 'husbands': 1854, 'today': 1855, 'smith': 1856, 'converse': 1857, 'dote': 1858, '_': 1859, '’twas': 1860, 'miracle': 1861, 'wooing': 1862, 'discretion': 1863, 'protect': 1864, 'online': 1865, 'performing': 1866, 'links': 1867, 'applicable': 1868, 'defective': 1869, 'disclaimer': 1870, 'limitation': 1871, 'maine': 1872, 'thunder': 1873, 'gait': 1874, 'folly': 1875, 'worthies': 1876, 'pisa': 1877, 'mustardseed': 1878, 'the]': 1879, 'sexton': 1880, 'swords': 1881, 'maids': 1882, 'torture': 1883, 'afternoon': 1884, 'east': 1885, 'spread': 1886, 'struck': 1887, 'groan': 1888, 'waste': 1889, 'bliss': 1890, 'winter': 1891, 'cup': 1892, 'fairer': 1893, 'teeth': 1894, 'stone': 1895, 'pen': 1896, 'glory': 1897, 'liking': 1898, 'delay': 1899, 'sleeps': 1900, 'substance': 1901, 'retire': 1902, 'seeming': 1903, 'sweetly': 1904, 'yond': 1905, 'humours': 1906, 'afeard': 1907, 'school': 1908, 'tongues': 1909, 'darkness': 1910, 'finds': 1911, 'counterfeit': 1912, 'conceive': 1913, 'mar': 1914, 'merchant': 1915, 'hill': 1916, 'beshrew': 1917, 'hie': 1918, 'scape': 1919, 'spy': 1920, \"'twill\": 1921, 'cat': 1922, 'slander': 1923, 'discover': 1924, \"brother's\": 1925, 'bethink': 1926, 'lodging': 1927, 'west': 1928, 'sold': 1929, 'press': 1930, \"perjur'd\": 1931, 'wash': 1932, 'wounds': 1933, 'acquaintance': 1934, 'woeful': 1935, 'evermore': 1936, 'vengeance': 1937, 'advise': 1938, 'undertake': 1939, 'vault': 1940, 'busy': 1941, 'iron': 1942, 'fares': 1943, 'mischief': 1944, 'sell': 1945, 'drop': 1946, 'clear': 1947, 'greatest': 1948, 'sleeping': 1949, 'huntsman': 1950, 'maintain': 1951, 'silent': 1952, 'seas': 1953, 'safe': 1954, 'authority': 1955, 'policy': 1956, 'oak': 1957, 'conference': 1958, 'pause': 1959, 'bend': 1960, 'wolf': 1961, \"warwick's\": 1962, 'shines': 1963, 'hears': 1964, 'frame': 1965, 'reward': 1966, 'ireland': 1967, 'judas': 1968, 'hail': 1969, 'morocco': 1970, 'salerio': 1971, 'cool': 1972, 'habit': 1973, 'acquainted': 1974, 'key': 1975, 'you’ll': 1976, 'value': 1977, 'rare': 1978, 'profit': 1979, 'marvel': 1980, 'princes': 1981, 'is’t': 1982, 'stol’n': 1983, 'ta’en': 1984, 'luck': 1985, 'error': 1986, 'stomach': 1987, 'shrew': 1988, 'keeping': 1989, 'apply': 1990, 'complying': 1991, 'derivative': 1992, 'reading': 1993, 'property': 1994, 'entity': 1995, 'paragraphs': 1996, '7': 1997, '9': 1998, 'expense': 1999, 'user': 2000, 'payments': 2001, 'address': 2002, 'legal': 2003, 'express': 2004, \"foundation's\": 2005, 'hart': 2006, 'produce': 2007, 'eleanor': 2008, 'sirs': 2009, 'practice': 2010, 'shine': 2011, \"'em\": 2012, 'moral': 2013, 'constable': 2014, 'cobweb': 2015, 'bury': 2016, 'armed': 2017, 'sides': 2018, 'citizens': 2019, 'grove': 2020, 'private': 2021, 'worm': 2022, \"heart's\": 2023, \"arm'd\": 2024, 'giving': 2025, 'treasure': 2026, 'burning': 2027, 'odd': 2028, 'crying': 2029, 'big': 2030, 'disposition': 2031, 'share': 2032, 'looking': 2033, 'everything': 2034, 'beams': 2035, 'wakes': 2036, 'prayer': 2037, 'hall': 2038, 'grown': 2039, 'nuptial': 2040, 'dove': 2041, 'rapier': 2042, 'trick': 2043, 'smooth': 2044, 'charm': 2045, \"us'd\": 2046, 'peril': 2047, 'bent': 2048, 'advance': 2049, 'groans': 2050, 'butcher': 2051, 'tall': 2052, 'ease': 2053, 'courteous': 2054, 'youngest': 2055, 'perchance': 2056, 'sour': 2057, \"t'\": 2058, 'happiness': 2059, 'table': 2060, 'doublet': 2061, \"know'st\": 2062, 'eight': 2063, 'conduct': 2064, 'nice': 2065, 'displeasure': 2066, 'humbly': 2067, \"'twixt\": 2068, 'interest': 2069, 'leap': 2070, 'snow': 2071, 'bare': 2072, 'resign': 2073, 'damned': 2074, 'minds': 2075, 'taking': 2076, 'estate': 2077, 'array': 2078, 'signify': 2079, 'sings': 2080, 'receipt': 2081, 'thereof': 2082, 'rate': 2083, 'week': 2084, \"dar'st\": 2085, 'chain': 2086, 'waking': 2087, 'resolve': 2088, 'closet': 2089, 'tush': 2090, 'friendship': 2091, 'yoke': 2092, 'unnatural': 2093, 'safety': 2094, 'meantime': 2095, 'figure': 2096, 'westmoreland': 2097, 'assist': 2098, 'council': 2099, 'towns': 2100, 'prey': 2101, 'savage': 2102, 'walks': 2103, 'wrath': 2104, 'officers': 2105, 'dogs': 2106, 'renowned': 2107, 'conclude': 2108, 'object': 2109, 'sting': 2110, 'ambitious': 2111, 'ones': 2112, \"mother's\": 2113, 'running': 2114, 'equal': 2115, 'aim': 2116, 'wears': 2117, 'peers': 2118, 'fame': 2119, 'necessity': 2120, 'betray': 2121, 'firm': 2122, 'device': 2123, 'persuade': 2124, 'repair': 2125, 'chief': 2126, 'weight': 2127, 'ship': 2128, 'dispatch': 2129, 'caught': 2130, 'stuff': 2131, 'th’': 2132, 'warranty': 2133, 'hazard': 2134, 'knowledge': 2135, 'followed': 2136, 'box': 2137, 'reasonable': 2138, 'complexion': 2139, 'wants': 2140, 'master’s': 2141, '“who': 2142, 'chooseth': 2143, 'sensible': 2144, 'shrewd': 2145, 'paying': 2146, 'trial': 2147, 'lieu': 2148, 'cuckold': 2149, '***': 2150, 'rules': 2151, 'nearly': 2152, 'printed': 2153, 'easily': 2154, 'concerning': 2155, 'computer': 2156, 'costs': 2157, 'electronically': 2158, 'revenue': 2159, 'email': 2160, 'solicit': 2161, 'beaufort': 2162, \"an't\": 2163, 'star': 2164, 'places': 2165, 'coat': 2166, 'rime': 2167, 'remuneration': 2168, \"'oman\": 2169, 'pinch': 2170, 'baptista’s': 2171, 'starveling': 2172, 'peaseblossom': 2173, 'steward': 2174, 'strife': 2175, 'mend': 2176, 'fish': 2177, 'naked': 2178, 'disgrace': 2179, 'farther': 2180, 'daylight': 2181, 'willingly': 2182, 'cure': 2183, 'madness': 2184, 'ope': 2185, 'store': 2186, 'debt': 2187, 'fourteen': 2188, \"capulet's\": 2189, \"e'er\": 2190, 'wax': 2191, 'story': 2192, 'team': 2193, 'knees': 2194, 'fingers': 2195, 'looked': 2196, 'musicians': 2197, 'plays': 2198, 'account': 2199, 'likeness': 2200, 'ape': 2201, 'gaze': 2202, 'refuse': 2203, 'lent': 2204, 'shore': 2205, 'thread': 2206, 'crave': 2207, 'hap': 2208, 'lo': 2209, 'allow': 2210, 'helen': 2211, 'fairly': 2212, 'sole': 2213, 'deceived': 2214, 'penny': 2215, 'sending': 2216, 'conceit': 2217, \"tybalt's\": 2218, 'determine': 2219, \"fortune's\": 2220, 'attended': 2221, 'immediately': 2222, 'repent': 2223, 'prayers': 2224, 'amorous': 2225, \"crown'd\": 2226, 'weeping': 2227, 'seize': 2228, 'divine': 2229, 'hollow': 2230, 'perjury': 2231, 'ignorance': 2232, 'miserable': 2233, 'convey': 2234, \"think'st\": 2235, 'grieve': 2236, 'happily': 2237, 'bridegroom': 2238, 'tide': 2239, \"on't\": 2240, 'sway': 2241, 'roses': 2242, 'knit': 2243, 'entertain': 2244, 'whoreson': 2245, 'wronged': 2246, 'joys': 2247, 'apothecary': 2248, 'doors': 2249, 'dust': 2250, 'fierce': 2251, 'dearest': 2252, 'liest': 2253, 'monster': 2254, 'rocks': 2255, 'friendly': 2256, 'rid': 2257, 'pg': 2258, 'montgomery': 2259, 'sat': 2260, 'fourth': 2261, 'him]': 2262, 'sceptre': 2263, 'earthly': 2264, \"show'd\": 2265, 'taught': 2266, 'notwithstanding': 2267, 'aid': 2268, 'task': 2269, 'pierce': 2270, 'dam': 2271, 'edge': 2272, 'belly': 2273, 'combat': 2274, 'shade': 2275, 'answered': 2276, 'fence': 2277, 'honours': 2278, 'suitors': 2279, 'commanded': 2280, 'consider': 2281, 'bind': 2282, 'wrongs': 2283, 'exempt': 2284, 'deserves': 2285, 'offended': 2286, 'commonwealth': 2287, 'wars': 2288, 'obedience': 2289, 'tent': 2290, 'malice': 2291, 'committed': 2292, 'blest': 2293, 'goods': 2294, 'amends': 2295, 'proclaim': 2296, 'blunt': 2297, 'forces': 2298, 'expect': 2299, 'traitors': 2300, 'gain': 2301, 'dukes': 2302, 'discharge': 2303, 'suitor': 2304, 'glass': 2305, 'moreover': 2306, 'turned': 2307, 'hue': 2308, 'jew’s': 2309, 'dish': 2310, 'bestow': 2311, 'where’s': 2312, 'difference': 2313, 'commit': 2314, 'outward': 2315, 'o’': 2316, 'shoulders': 2317, 'quality': 2318, 'render': 2319, 'contents': 2320, 'garments': 2321, 'penance': 2322, 'sola': 2323, 'accepted': 2324, 'royalties': 2325, 'addition': 2326, 'active': 2327, 'ascii': 2328, 'physical': 2329, '90': 2330, 'implied': 2331, 'contributions': 2332, 'subscribe': 2333, 'horner': 2334, \"suffolk's\": 2335, 'plot': 2336, 'calf': 2337, 'apart': 2338, 'dress': 2339, 'mile': 2340, 'roar': 2341, 'flout': 2342, 'linen': 2343, 'rogues': 2344, 'nan': 2345, 'tame': 2346, 'hic': 2347, 'midnight': 2348, '[oswald': 2349, 'a’': 2350, 'naught': 2351, 'toil': 2352, 'moved': 2353, 'weapon': 2354, 'houses': 2355, 'drew': 2356, 'troubled': 2357, 'griefs': 2358, 'shown': 2359, 'examine': 2360, 'penalty': 2361, \"liv'd\": 2362, 'stranger': 2363, 'ripe': 2364, '[gives': 2365, 'giddy': 2366, 'turning': 2367, \"whipp'd\": 2368, 'misery': 2369, 'burnt': 2370, 'eleven': 2371, 'sitting': 2372, 'felt': 2373, 'esteem': 2374, 'torch': 2375, 'pitch': 2376, 'mask': 2377, 'game': 2378, 'brains': 2379, 'hairs': 2380, 'backs': 2381, 'term': 2382, 'untimely': 2383, 'nell': 2384, 'hangs': 2385, 'touching': 2386, 'forswear': 2387, 'semblance': 2388, 'tremble': 2389, 'different': 2390, 'craves': 2391, 'shot': 2392, 'jests': 2393, 'ended': 2394, 'dwell': 2395, 'likewise': 2396, 'self': 2397, 'lightning': 2398, 'smiles': 2399, 'womb': 2400, 'virtues': 2401, 'abuse': 2402, 'senses': 2403, 'wounded': 2404, 'season': 2405, 'lamentable': 2406, 'dried': 2407, 'stale': 2408, 'score': 2409, 'minute': 2410, 'joyful': 2411, 'trusty': 2412, 'sweetest': 2413, 'pieces': 2414, 'violent': 2415, 'skill': 2416, 'italy': 2417, 'reputation': 2418, 'temper': 2419, 'slay': 2420, 'sends': 2421, 'newly': 2422, 'price': 2423, 'torment': 2424, 'serpent': 2425, 'drops': 2426, 'memory': 2427, 'familiar': 2428, 'unworthy': 2429, 'lodge': 2430, 'defence': 2431, \"stay'd\": 2432, 'wedding-day': 2433, 'nightly': 2434, 'notes': 2435, 'descend': 2436, 'miles': 2437, 'flood': 2438, 'marvellous': 2439, 'text': 2440, 'spake': 2441, 'evening': 2442, 'mass': 2443, 'reverend': 2444, 'buried': 2445, 'cock': 2446, \"watch'd\": 2447, 'fright': 2448, 'wedding': 2449, 'merriment': 2450, 'solemn': 2451, 'defy': 2452, 'aloof': 2453, 'afraid': 2454, 'partly': 2455, 'apprehend': 2456, 'haply': 2457, 'afterwards': 2458, 'possession': 2459, 'fill': 2460, 'reasons': 2461, 'liberal': 2462, 'bootless': 2463, 'shun': 2464, 'former': 2465, 'rob': 2466, 'hardly': 2467, 'perfect': 2468, 'sky': 2469, 'league': 2470, 'troy': 2471, 'beside': 2472, 'amain': 2473, 'shoulder': 2474, 'slept': 2475, 'conqueror': 2476, 'profits': 2477, 'possessed': 2478, 'blown': 2479, 'mourning': 2480, 'contented': 2481, 'undo': 2482, 'conclusion': 2483, 'allegiance': 2484, 'corrupt': 2485, 'disdain': 2486, 'forthwith': 2487, 'void': 2488, 'lust': 2489, 'eldest': 2490, 'guess': 2491, 'harmony': 2492, 'rightly': 2493, 'lad': 2494, 'froward': 2495, 'graces': 2496, 'upright': 2497, 'delivered': 2498, 'prisoners': 2499, 'guarded': 2500, 'villains': 2501, 'sins': 2502, 'ransom': 2503, 'arragon': 2504, 'sooth': 2505, 'laughter': 2506, 'dumb': 2507, 'ignorant': 2508, 'portia’s': 2509, 'latin': 2510, 'casket': 2511, 'call’d': 2512, 'look’d': 2513, 'simplicity': 2514, 'hates': 2515, 'instantly': 2516, 'faces': 2517, 'love’s': 2518, 'keen': 2519, 'virgin': 2520, 'weigh': 2521, 'weather': 2522, 'amiss': 2523, 'neighbours': 2524, 'mere': 2525, 'speaking': 2526, 'convenient': 2527, 'rightful': 2528, 'loved': 2529, 'file': 2530, 'files': 2531, 'owns': 2532, 'registered': 2533, 'intellectual': 2534, 'destroy': 2535, 'based': 2536, 'references': 2537, 'removed': 2538, 'included': 2539, '6': 2540, 'marked': 2541, 'derive': 2542, 'agreed': 2543, 'considerable': 2544, 'damage': 2545, 'expenses': 2546, 'permitted': 2547, 'beadle': 2548, 'regent': 2549, 'petitioner': 2550, 'sickness': 2551, 'affected': 2552, 'navarre': 2553, 'forester': 2554, \"do't\": 2555, 'buck': 2556, 'pearl': 2557, 'visor': 2558, 'inn': 2559, 'vat': 2560, 'vill': 2561, 'revenged': 2562, 'cozened': 2563, 'effects': 2564, 'he’ll': 2565, 'snug': 2566, 'goneril]': 2567, \"i'ld\": 2568, 'messina': 2569, 'dignity': 2570, 'pair': 2571, 'piteous': 2572, 'stage': 2573, 'miss': 2574, 'choler': 2575, 'tyrant': 2576, 'thumb': 2577, 'abraham': 2578, 'purple': 2579, 'began': 2580, 'affections': 2581, 'sorrows': 2582, 'denied': 2583, 'dine': 2584, 'create': 2585, \"rais'd\": 2586, 'gall': 2587, \"she'll\": 2588, 'chaste': 2589, 'huge': 2590, 'wisely': 2591, 'puts': 2592, 'crow': 2593, 'scales': 2594, 'trow': 2595, 'guests': 2596, 'burden': 2597, 'sink': 2598, 'prick': 2599, 'sooner': 2600, 'grandsire': 2601, 'watery': 2602, 'tail': 2603, 'swears': 2604, 'carriage': 2605, \"night's\": 2606, 'direct': 2607, 'shift': 2608, 'sought': 2609, 'thirty': 2610, 'goodman': 2611, 'withdraw': 2612, 'unknown': 2613, \"belov'd\": 2614, 'bait': 2615, 'orchard': 2616, 'conjure': 2617, 'climb': 2618, \"wash'd\": 2619, 'discovered': 2620, 'perform': 2621, '[within': 2622, 'meanest': 2623, 'morn': 2624, 'thrown': 2625, 'strain': 2626, 'quit': 2627, 'nest': 2628, 'vi': 2629, 'ends': 2630, 'draws': 2631, 'hanged': 2632, 'afford': 2633, \"prince's\": 2634, 'spleen': 2635, 'exile': 2636, 'wink': 2637, 'mantle': 2638, 'manly': 2639, 'deceit': 2640, 'native': 2641, 'wot': 2642, 'tidings': 2643, \"body's\": 2644, 'pack': 2645, \"disguis'd\": 2646, 'ado': 2647, 'mountain': 2648, \"ta'en\": 2649, 'harsh': 2650, 'hunting': 2651, 'opportunity': 2652, 'feeling': 2653, 'reach': 2654, 'raging': 2655, 'utter': 2656, 'serves': 2657, 'shield': 2658, 'resolution': 2659, 'likely': 2660, 'needful': 2661, 'provision': 2662, 'wondrous': 2663, 'bell': 2664, 'chat': 2665, 'unhappy': 2666, 'hated': 2667, 'eternal': 2668, 'forty': 2669, 'contempt': 2670, 'churchyard': 2671, 'rotten': 2672, 'supposed': 2673, 'sheet': 2674, 'unkind': 2675, '[stabs': 2676, 'intended': 2677, 'ought': 2678, 'regal': 2679, 'fathers': 2680, 'plead': 2681, 'stoop': 2682, 'whisper': 2683, 'stern': 2684, 'commands': 2685, 'granted': 2686, 'tire': 2687, 'success': 2688, 'diadem': 2689, 'wealthy': 2690, 'troop': 2691, 'dukedom': 2692, 'gently': 2693, 'forest': 2694, 'manhood': 2695, 'willing': 2696, 'losses': 2697, 'nails': 2698, 'prosper': 2699, 'thereby': 2700, 'beyond': 2701, 'mistrust': 2702, 'nobody': 2703, 'bull': 2704, 'tough': 2705, 'bosoms': 2706, 'supply': 2707, 'avoid': 2708, 'rail': 2709, 'principal': 2710, 'disguised': 2711, 'remorse': 2712, 'gloucester]': 2713, 'sue': 2714, 'herein': 2715, 'suffice': 2716, 'loath': 2717, 'promised': 2718, 'loyalty': 2719, 'mocking': 2720, 'invention': 2721, \"wife's\": 2722, 'elizabeth': 2723, \"inform'd\": 2724, 'affairs': 2725, '[reads]': 2726, 'mates': 2727, 'zeal': 2728, 'owl': 2729, 'assistance': 2730, 'burst': 2731, 'deformed': 2732, 'stephano': 2733, 'grass': 2734, 'exceeding': 2735, 'prodigal': 2736, 'picture': 2737, 'sober': 2738, 'absence': 2739, 'scholar': 2740, 'condition': 2741, '[_to': 2742, 'directly': 2743, 'bar': 2744, 'e’er': 2745, 'heartily': 2746, 'multitude': 2747, 'gifts': 2748, 'flat': 2749, 'rebels': 2750, 'example': 2751, 'naughty': 2752, 'bestowed': 2753, 'bellario': 2754, 'quaint': 2755, 'twelvemonth': 2756, 'strict': 2757, 'alter': 2758, 'rings': 2759, 'moonlight': 2760, 'nought': 2761, '*****': 2762, 'formats': 2763, 'http': 2764, 'concept': 2765, 'research': 2766, 'redistribution': 2767, 'promoting': 2768, 'available': 2769, 'redistributing': 2770, 'obtaining': 2771, 'preserve': 2772, 'd': 2773, 'immediate': 2774, 'prominently': 2775, 'copied': 2776, 'vanilla': 2777, 'specified': 2778, 'accordance': 2779, 'employees': 2780, 'effort': 2781, 'defects': 2782, 'negligence': 2783, 'explanation': 2784, 'additions': 2785, 'widest': 2786, 'computers': 2787, 'generations': 2788, '2001': 2789, 'federal': 2790, 'fairbanks': 2791, 'locations': 2792, 'org/donate': 2793, 'pole': 2794, 'style': 2795, 'telling': 2796, 'knavery': 2797, 'accuse': 2798, \"'the\": 2799, 'stool': 2800, 'groom': 2801, 'punishment': 2802, 'space': 2803, \"heaven's\": 2804, 'thorough': 2805, 'cheese': 2806, 'devils': 2807, 'bill': 2808, 'companion': 2809, 'mistake': 2810, 'dumain': 2811, 'aquitaine': 2812, \"a'\": 2813, 'wenches': 2814, 'mistook': 2815, 'finely': 2816, 'fifty': 2817, 'goddess': 2818, 'coxcomb': 2819, 'crack': 2820, 'lunatic': 2821, 'comedy': 2822, 'otherwise': 2823, 'cue': 2824, 'imagination': 2825, 'hounds': 2826, 'cambio': 2827, '‘a': 2828, 'thisbe’s': 2829, 'serv': 2830, 'doct': 2831, \"master's\": 2832, 'manage': 2833, 'bills': 2834, 'quench': 2835, 'veins': 2836, 'disturb': 2837, 'stole': 2838, \"morning's\": 2839, 'shrift': 2840, 'feather': 2841, \"cupid's\": 2842, \"rul'd\": 2843, \"pass'd\": 2844, 'hopes': 2845, 'guest': 2846, 'lusty': 2847, 'meddle': 2848, 'infection': 2849, 'rank': 2850, 'shin': 2851, 'madman': 2852, 'compare': 2853, \"drown'd\": 2854, 'knowest': 2855, 'served': 2856, 'extremity': 2857, 'stays': 2858, 'shoes': 2859, 'nimble': 2860, 'mouse': 2861, 'lights': 2862, 'smallest': 2863, 'kisses': 2864, 'thin': 2865, 'revels': 2866, 'dainty': 2867, '[music': 2868, 'ago': 2869, 'frowns': 2870, 'wilful': 2871, 'bachelor': 2872, 'banquet': 2873, 'strangers': 2874, 'beloved': 2875, 'ran': 2876, 'leg': 2877, 'fruit': 2878, 'breaks': 2879, 'livery': 2880, 'cloak': 2881, 'faithful': 2882, 'throughout': 2883, 'aloud': 2884, \"o'clock\": 2885, 'hop': 2886, 'silk': 2887, 'parting': 2888, 'non': 2889, 'natural': 2890, 'medicine': 2891, 'plant': 2892, 'couch': 2893, 'sweeter': 2894, 'francis': 2895, 'stain': 2896, 'alliance': 2897, 'pin': 2898, 'rests': 2899, 'hay': 2900, 'slip': 2901, 'kindly': 2902, 'chase': 2903, 'proves': 2904, 'hole': 2905, 'gear': 2906, 'fan': 2907, 'hare': 2908, 'cords': 2909, 'faster': 2910, 'folks': 2911, 'playing': 2912, 'beats': 2913, 'delights': 2914, 'loathsome': 2915, 'everlasting': 2916, 'unfold': 2917, 'quarter': 2918, 'consort': 2919, 'follower': 2920, 'injuries': 2921, 'dearly': 2922, 'calm': 2923, 'hereafter': 2924, \"stain'd\": 2925, 'fate': 2926, 'apace': 2927, \"play'd\": 2928, 'impatient': 2929, 'robes': 2930, 'wring': 2931, 'corse': 2932, 'beautiful': 2933, 'mistaking': 2934, \"mov'd\": 2935, 'affliction': 2936, 'wedded': 2937, 'axe': 2938, 'carrion': 2939, \"juliet's\": 2940, 'thinking': 2941, 'armour': 2942, 'milk': 2943, 'philosophy': 2944, \"death's\": 2945, 'respects': 2946, 'nightingale': 2947, 'couldst': 2948, 'wrought': 2949, 'practise': 2950, 'society': 2951, \"abus'd\": 2952, 'yellow': 2953, 'shroud': 2954, 'government': 2955, 'hire': 2956, 'fears': 2957, 'custom': 2958, 'pitiful': 2959, 'flattering': 2960, 'bringing': 2961, \"deceiv'd\": 2962, 'dwells': 2963, 'hung': 2964, 'trunk': 2965, 'hasty': 2966, 'affords': 2967, 'graves': 2968, '[the': 2969, 'employment': 2970, 'intents': 2971, 'enforce': 2972, 'lean': 2973, 'guide': 2974, 'descent': 2975, 'mischance': 2976, 'messengers': 2977, 'retreat': 2978, 'proudest': 2979, 'root': 2980, 'rebel': 2981, 'mourn': 2982, 'wolves': 2983, 'silly': 2984, 'ruin': 2985, '[dies]': 2986, 'ships': 2987, 'spurn': 2988, 'boots': 2989, \"resolv'd\": 2990, 'event': 2991, 'self-same': 2992, 'degree': 2993, 'blot': 2994, 'parley': 2995, 'hunt': 2996, 'shepherd': 2997, 'tend': 2998, 'kills': 2999, 'bereft': 3000, 'perish': 3001, 'intends': 3002, 'candle': 3003, 'satisfy': 3004, 'forlorn': 3005, 'dishonour': 3006, 'curtsy': 3007, 'dower': 3008, 'therein': 3009, 'likes': 3010, 'harbour': 3011, 'deceive': 3012, 'cares': 3013, 'coast': 3014, 'firmly': 3015, 'fitted': 3016, \"pleas'd\": 3017, 'cloud': 3018, 'requite': 3019, 'answers': 3020, 'doubtful': 3021, 'salve': 3022, 'treasons': 3023, 'clamour': 3024, 'upward': 3025, 'ragged': 3026, 'throat': 3027, 'clown': 3028, 'venture': 3029, 'waters': 3030, 'tales': 3031, 'hose': 3032, 'vilely': 3033, 'caskets': 3034, 'wooers': 3035, '[_aside': 3036, 'advantage': 3037, 'badge': 3038, 'barren': 3039, 'forfeiture': 3040, 'certainly': 3041, 'indirectly': 3042, 'margery': 3043, 'trifle': 3044, 'pocket': 3045, 'ashamed': 3046, 'disguise': 3047, 'preparation': 3048, 'jewels': 3049, 'bassanio’s': 3050, 'barbarous': 3051, 'offices': 3052, 'cupid’s': 3053, 'lying': 3054, 'million': 3055, 'fed': 3056, 'antonio’s': 3057, 'pleas’d': 3058, 'confusion': 3059, 'drive': 3060, 'relent': 3061, 'trade': 3062, 'cruelty': 3063, 'wager': 3064, 'oppose': 3065, 'wag': 3066, 'proved': 3067, 'remembrance': 3068, 'txt': 3069, 'produced': 3070, 'countries': 3071, 'whatsoever': 3072, 'beginning': 3073, 'however': 3074, 'require': 3075, 'reported': 3076, 'disk': 3077, 'opportunities': 3078, 'lake': 3079, 'ut': 3080, 'checks': 3081, 'walter': 3082, 'southwell': 3083, 'alexander': 3084, 'sheriff': 3085, 'anjou': 3086, 'entertainment': 3087, 'ambition': 3088, 'glance': 3089, \"grace's\": 3090, 'attendant': 3091, 'pot': 3092, 'laughing': 3093, 'skin': 3094, 'affect': 3095, 'unkindness': 3096, 'message': 3097, 'rags': 3098, 'beguile': 3099, 'carried': 3100, 'schoolmaster': 3101, 'verses': 3102, 'privilege': 3103, 'obedient': 3104, 'lute': 3105, 'mocks': 3106, 'blue': 3107, 'welsh': 3108, \"page's\": 3109, 'pounds': 3110, 'herne': 3111, 'players': 3112, 'woo’d': 3113, 'licio': 3114, 'grew': 3115, 'betwixt': 3116, 'hermia’s': 3117, '[edmund': 3118, 'hero’s': 3119, 'alike': 3120, 'strive': 3121, 'capulets': 3122, 'blade': 3123, 'pernicious': 3124, 'airy': 3125, 'nephew': 3126, \"breath'd\": 3127, 'walking': 3128, 'adding': 3129, 'bud': 3130, 'serious': 3131, 'arrow': 3132, 'beauties': 3133, 'eyesight': 3134, 'reckoning': 3135, 'heel': 3136, 'buds': 3137, 'burns': 3138, 'backward': 3139, 'falsehood': 3140, 'fires': 3141, 'begun': 3142, 'shining': 3143, 'rejoice': 3144, \"'ay\": 3145, 'babe': 3146, 'seeks': 3147, \"beauty's\": 3148, 'possess': 3149, 'briefly': 3150, 'borrow': 3151, 'visage': 3152, 'bone': 3153, 'tainted': 3154, 'foreign': 3155, 'begot': 3156, 'hanging': 3157, 'torches': 3158, 'solemnity': 3159, 'stock': 3160, 'saucy': 3161, 'convert': 3162, 'blushing': 3163, 'devotion': 3164, 'rhyme': 3165, 'extreme': 3166, \"stol'n\": 3167, 'pronounce': 3168, 'venus': 3169, 'trees': 3170, \"cam'st\": 3171, 'enmity': 3172, 'direction': 3173, 'yielding': 3174, 'changes': 3175, 'contract': 3176, 'repose': 3177, 'bounty': 3178, 'infinite': 3179, 'procure': 3180, 'attending': 3181, 'drunkard': 3182, 'worser': 3183, 'remedies': 3184, 'confession': 3185, 'plainly': 3186, \"chang'd\": 3187, 'distance': 3188, 'scurvy': 3189, 'nobleman': 3190, 'clock': 3191, 'shadows': 3192, 'youthful': 3193, 'honey': 3194, 'circumstance': 3195, 'appetite': 3196, 'flint': 3197, 'ornament': 3198, 'beggars': 3199, 'egg': 3200, 'tutor': 3201, 'couple': 3202, 'carries': 3203, 'scratch': 3204, 'soundly': 3205, 'swifter': 3206, 'stout': 3207, 'purchase': 3208, 'steeds': 3209, 'rites': 3210, '[throws': 3211, 'dismal': 3212, 'bower': 3213, 'containing': 3214, 'monarch': 3215, \"murder'd\": 3216, 'merciful': 3217, 'mightst': 3218, 'sympathy': 3219, \"vow'd\": 3220, 'fallen': 3221, 'revel': 3222, 'dozen': 3223, 'division': 3224, 'ladyship': 3225, \"look'd\": 3226, 'flow': 3227, 'decree': 3228, 'thankful': 3229, 'reply': 3230, 'bread': 3231, 'bridal': 3232, 'slack': 3233, 'compass': 3234, 'revolt': 3235, 'commission': 3236, \"speak'st\": 3237, 'roaring': 3238, 'new-made': 3239, 'liquor': 3240, 'drowsy': 3241, 'cook': 3242, 'furnish': 3243, 'deck': 3244, 'tried': 3245, 'madly': 3246, 'club': 3247, 'ghost': 3248, 'seeking': 3249, 'whit': 3250, 'stick': 3251, 'instruments': 3252, 'lower': 3253, 'fa': 3254, 'speedy': 3255, 'angels': 3256, 'ink': 3257, 'noted': 3258, 'poverty': 3259, 'lantern': 3260, 'sepulchre': 3261, \"stopp'd\": 3262, 'miscarried': 3263, 'writes': 3264, 'richmond': 3265, 'somerville': 3266, \"charg'd\": 3267, \"deserv'd\": 3268, 'gaunt': 3269, \"depos'd\": 3270, 'cowardice': 3271, 'troops': 3272, 'roger': 3273, 'sith': 3274, 'kingly': 3275, 'heirs': 3276, 'articles': 3277, \"prov'd\": 3278, 'sufferance': 3279, 'depends': 3280, 'wipe': 3281, 'ruthless': 3282, 'payment': 3283, 'thieves': 3284, 'slanders': 3285, 'causes': 3286, 'mess': 3287, 'mounted': 3288, 'escape': 3289, 'aunt': 3290, 'famous': 3291, 'mildness': 3292, 'coats': 3293, \"proclaim'd\": 3294, 'throws': 3295, 'smiling': 3296, 'nigh': 3297, \"wrong'd\": 3298, 'excursions': 3299, 'tragedy': 3300, 'actors': 3301, 'melt': 3302, 'execute': 3303, 'swearing': 3304, 'flock': 3305, 'treachery': 3306, 'conflict': 3307, 'marks': 3308, 'slaughter': 3309, 'alarums': 3310, 'flying': 3311, 'build': 3312, 'greet': 3313, 'caesar': 3314, 'seldom': 3315, 'pleases': 3316, 'stops': 3317, \"perform'd\": 3318, 'sovereignty': 3319, 'rent': 3320, 'shapes': 3321, 'amity': 3322, 'chosen': 3323, 'pawn': 3324, \"fix'd\": 3325, 'ambassador': 3326, 'fleet': 3327, 'setting': 3328, 'tied': 3329, 'tents': 3330, 'camp': 3331, 'fates': 3332, 'impose': 3333, 'remains': 3334, 'decay': 3335, 'corner': 3336, \"hang'd\": 3337, \"ha'\": 3338, 'instrument': 3339, 'fortunate': 3340, 'vii': 3341, 'loyal': 3342, 'flatter': 3343, 'higher': 3344, 'peremptory': 3345, 'biting': 3346, 'patron': 3347, 'harder': 3348, 'leads': 3349, \"fear'd\": 3350, \"winter's\": 3351, 'length': 3352, 'pomp': 3353, 'rock': 3354, 'period': 3355, 'murderers': 3356, 'gaoler': 3357, 'worthier': 3358, 'port': 3359, 'despise': 3360, 'sacred': 3361, 'apple': 3362, 'shames': 3363, 'christians': 3364, 'fields': 3365, 'dice': 3366, 'temple': 3367, 'woman’s': 3368, '’twill': 3369, 'cudgel': 3370, 'fifteen': 3371, 'studied': 3372, 'secretly': 3373, 'o’clock': 3374, 'sup': 3375, 'daughter’s': 3376, 'scroll': 3377, 'employ': 3378, 'everyone': 3379, 'unlike': 3380, 'bleed': 3381, 'fourscore': 3382, 'counsels': 3383, 'sweat': 3384, 'stake': 3385, '’twixt': 3386, 'endeavour': 3387, 'steps': 3388, 'tricks': 3389, 'tyranny': 3390, 'stubborn': 3391, 'offers': 3392, 'slaves': 3393, 'turn’d': 3394, 'daniel': 3395, 'indirect': 3396, 'gloves': 3397, 'lion’s': 3398, 'begg’d': 3399, '//www': 3400, 'especially': 3401, 'indicate': 3402, 'proprietary': 3403, 'hypertext': 3404, 'original': 3405, 'method': 3406, 'calculate': 3407, 'legally': 3408, 'required': 3409, 'returns': 3410, 'proofread': 3411, 'errors': 3412, 'consequential': 3413, 'receiving': 3414, 'fitness': 3415, 'disclaimers': 3416, 'agent': 3417, 'alteration': 3418, '1500': 3419, 'important': 3420, '50': 3421, 'confirmed': 3422, 'edition': 3423, 'facility': 3424, 'newsletter': 3425, 'mate': 3426, 'jourdain': 3427, 'ravish': 3428, 'normandy': 3429, 'isle': 3430, 'intolerable': 3431, 'ruffian': 3432, 'plainness': 3433, \"duke's\": 3434, 'soil': 3435, 'secrets': 3436, 'questions': 3437, 'mum': 3438, 'crafty': 3439, 'listen': 3440, 'betters': 3441, \"women's\": 3442, 'dunghill': 3443, \"years'\": 3444, 'joan': 3445, 'limb': 3446, 'strikes': 3447, 'wrathful': 3448, 'seemeth': 3449, 'bedlam': 3450, 'arrest': 3451, \"pow'rs\": 3452, 'adder': 3453, 'signs': 3454, 'passed': 3455, 'curses': 3456, 'earnest': 3457, 'vulgar': 3458, \"for't\": 3459, 'adam': 3460, 'thames': 3461, 'brown': 3462, 'beef': 3463, 'juvenal': 3464, 'working': 3465, 'gentles': 3466, 'waist': 3467, 'crab': 3468, 'pricket': 3469, 'audience': 3470, 'lived': 3471, 'gallants': 3472, 'eyne': 3473, 'tapers': 3474, 'holla': 3475, 'goot': 3476, 'fery': 3477, 'trot': 3478, \"falstaff's\": 3479, 'charms': 3480, 'intelligence': 3481, 'suffered': 3482, 'profess': 3483, 'brainford': 3484, 'played': 3485, 'elves': 3486, 'release': 3487, 'instruct': 3488, 'rivals': 3489, 'puppet': 3490, 'minola': 3491, 'sunday': 3492, 'sleeves': 3493, 'gaol': 3494, 'brother’s': 3495, 'services': 3496, 'dotage': 3497, 'oswald': 3498, \"albany's\": 3499, 'murther': 3500, 'kent]': 3501, 'hovel': 3502, 'edgar]': 3503}\n"
          ]
        }
      ],
      "source": [
        "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
        "int_words = [vocab_to_int[word] for word in words]\n",
        "print(vocab_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu9ZaMn86F2o"
      },
      "source": [
        "# 4. Perform Word Subsampling\n",
        "\n",
        "* Words that show up often such as \"the\", \"of\", and \"for\" don't provide much context to the nearby words.\n",
        "* Discarding some of them (aka Subsampling) can achieve :\n",
        "  * **removing of noise in data**\n",
        "  * faster training\n",
        "  * better representations.\n",
        "* Each word $w_i$ in the training set is discarded with probability:\n",
        "  * $t$ : threshold (something small like 1e-5)\n",
        "  * $f(w_i)$ : frequency (in decimals) of word $w_i$\n",
        "\n",
        "$$ P(w_i) = 1 - \\sqrt{\\frac{t}{f(w_i)}} $$\n",
        "\n",
        "* Use: discard if `random.random() < probs[word]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUkPNZ7W6F2o"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def subsample_words(int_words, threshold = 1e-5):\n",
        "  word_counts = Counter(int_words)\n",
        "  total_n_words = len(int_words)\n",
        "\n",
        "  freq_ratios = {word: count/total_n_words for word, count in word_counts.items()}\n",
        "  p_drop = {word: 1 - np.sqrt(threshold/freq_ratios[word]) for word in word_counts}\n",
        "\n",
        "  return [word for word in int_words if random.random() < (1 - p_drop[word])]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  train_words = subsample_words(int_words)\n",
        "  print(len(int_words))\n",
        "  print(len(train_words))\n",
        "  print(len(train_words)/len(int_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7JpJPzKuDVz",
        "outputId": "1418a10c-d959-4259-ace7-6b1d38657b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291011\n",
            "33668\n",
            "0.11569322121844192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNeCaHC26F2p"
      },
      "source": [
        "# 5. Generate Context Targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ACL0dJ6F2p"
      },
      "source": [
        "For each word in the text, define **_Context_** by grabbing the surrounding words in a window of size $C$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOSF5QU06F2q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def get_target(words, idx, max_window_size=5):\n",
        "    R = random.randint(1, max_window_size)\n",
        "    start = max(0,idx-R)\n",
        "    end = min(idx+R,len(words)-1)\n",
        "    targets = words[start:idx] + words[idx+1:end+1] # +1 since doesn't include this idx\n",
        "    return targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Bd8eaE6F2q",
        "outputId": "d5a43e3c-186a-4390-e540-47faa0b6658d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Target:  [0, 1, 2, 3, 4, 6, 7, 8, 9]\n",
            "Target:  [2, 3, 4, 6, 7, 8]\n",
            "Target:  [4, 6]\n",
            "Target:  [4, 6]\n",
            "Target:  [0, 1, 2, 3, 4, 6, 7, 8, 9]\n"
          ]
        }
      ],
      "source": [
        "int_text = [i for i in range(10)]\n",
        "print('Input: ', int_text)\n",
        "idx=5 # word index of interest\n",
        "\n",
        "for _ in range(5):\n",
        "  target = get_target(int_text, idx=idx, max_window_size=5)\n",
        "  print('Target: ', target)  # you should get some indices around the idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHq3Mqm16F2r"
      },
      "source": [
        "# 6. Generate Batches\n",
        "\n",
        "* Grab `batch_size` words from a words list\n",
        "* Then for each of those words, get the context target words in a window."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(words, batch_size, max_window_size=5):\n",
        "  # only full batches\n",
        "  n_batches = len(words)//batch_size\n",
        "  words = words[:n_batches*batch_size]\n",
        "  for i in range(0, len(words), batch_size):\n",
        "    batch_of_center_words = words[i:i+batch_size]   # current batch of words\n",
        "    batch_x, batch_y = [], []\n",
        "\n",
        "    for ii in range(len(batch_of_center_words)):  # range(batch_size) unless truncated at the end\n",
        "      x = [batch_of_center_words[ii]]             # single word\n",
        "      y = get_target(words=batch_of_center_words, idx=ii, max_window_size=max_window_size)  # list of context words\n",
        "\n",
        "      batch_x.extend(x * len(y)) # repeat the center word (n_context_words) times\n",
        "      batch_y.extend(y)\n",
        "\n",
        "    yield batch_x, batch_y       # ex) [1,1,2,2,2,2,3,3,3,3], [0,2,0,1,3,4,1,2,4,5]"
      ],
      "metadata": {
        "id": "t844-ojIDZqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, max_window_size=5))\n",
        "\n",
        "print('x\\n', x)\n",
        "print('y\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1nQbPhMaLxH",
        "outputId": "168f96c9-6527-4b4e-b6dc-52ecf5904d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [0, 0, 0, 1, 1, 1, 2, 2, 2, 3]\n",
            "y\n",
            " [1, 2, 3, 0, 2, 3, 0, 1, 3, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CDhkFR86F2r"
      },
      "source": [
        "# 7. Define COSINE SIMILARITY Function for Validation Metric\n",
        "\n",
        "* Choose a few common words & a few uncommon words\n",
        "* Print their **closest words** using Cosine Similarity:\n",
        "\n",
        "<img src=\"https://github.com/lukysummer/SkipGram_with_NegativeSampling_Pytorch/blob/master/assets/two_vectors.png?raw=1\" width=30%>\n",
        "\n",
        "$$\n",
        "\\mathrm{similarity} = \\cos(\\theta) = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}||\\vec{b}|}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(embedding, n_valid_words=16, valid_window=100):\n",
        "  \"\"\" Returns the cosine similarity of validation words with words in the embedding matrix.\n",
        "      embedding: PyTorch embedding module\n",
        "      n_valid_words: # of validation words (recommended to have even numbers)\n",
        "  \"\"\"\n",
        "  all_embeddings = embedding.weight  # (n_vocab, n_embed)\n",
        "  # sim = (a . b) / |a||b|\n",
        "  magnitudes = all_embeddings.pow(2).sum(dim=1).sqrt().unsqueeze(0) # (1, n_vocab)\n",
        "\n",
        "  # Pick validation words from 2 ranges: (0, window): common words & (1000, 1000+window): uncommon words\n",
        "  valid_words = random.sample(range(valid_window), n_valid_words//2) + random.sample(range(1000, 1000+valid_window), n_valid_words//2)\n",
        "  valid_words = torch.LongTensor(np.array(valid_words)).to(device) # (n_valid_words, 1)\n",
        "\n",
        "  valid_embeddings = embedding(valid_words) # (n_valid_words, n_embed)\n",
        "  # (n_valid_words, n_embed) * (n_embed, n_vocab) --> (n_valid_words, n_vocab) / 1, n_vocab)\n",
        "  similarities = torch.mm(valid_embeddings, all_embeddings.t()) / magnitudes  # (n_valid_words, n_vocab)\n",
        "\n",
        "  return valid_words, similarities"
      ],
      "metadata": {
        "id": "uW8qHbEzHgWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCVrIGd56F2s"
      },
      "source": [
        "# 8. Define SkipGram model with [Negative Sampling](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI17mASb6F2s"
      },
      "source": [
        "Instead of updating all tokens' embeddings, approximate the loss from softmax layer by only updating a small subset of weights assciated with:\n",
        "* center word\n",
        "* context words\n",
        "* noise words\n",
        "\n",
        "In the model, we use 2 separate embedding tables, one for input words & one for output words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo5EAZG26F2t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `nn.Embedding` layer is the same as a Linear layer with one-hot-encoded input. You could define the layer as `nn.Linear(1000, 30)` & represent each word as a one-hot vector, e.g., `[0,0,1,0,...,0]` where the length of the vector is 1000.\n",
        "\n",
        "* It is an ***embedding lookup table*** which is just a weight matrix & the lookup is just a shortcut for the matrix multiplication.\n",
        "\n",
        "* It is trained just like any weight matrix."
      ],
      "metadata": {
        "id": "iT4yFD5RxhX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "Complete the following with the correct implementation."
      ],
      "metadata": {
        "id": "EZhauvXASWqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwuTTBHu6F2t"
      },
      "outputs": [],
      "source": [
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed, noise_dist=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_vocab = n_vocab\n",
        "        self.n_embed = n_embed\n",
        "        self.noise_dist = noise_dist\n",
        "\n",
        "\n",
        "        self.in_embed = ''' COMPLETE_HERE '''\n",
        "        self.out_embed = ''' COMPLETE_HERE '''\n",
        "        # Initialize both embedding tables with uniform distribution\n",
        "        self.in_embed.weight.data.uniform_(-1, 1)\n",
        "        self.out_embed.weight.data.uniform_(-1, 1)\n",
        "\n",
        "\n",
        "    def forward_input(self, input_words):\n",
        "        ''' COMPLETE_HERE '''\n",
        "        return input_vectors  # input vector embeddings\n",
        "\n",
        "\n",
        "    def forward_target(self, output_words):\n",
        "        ''' COMPLETE_HERE '''\n",
        "        return output_vectors  # output vector embeddings\n",
        "\n",
        "\n",
        "    def forward_noise(self, batch_size, n_samples=5):\n",
        "        \"\"\" Generate noise vectors with shape (batch_size, n_samples, n_embed)\"\"\"\n",
        "        # If no Noise Distribution specified, sample noise words uniformly from vocabulary\n",
        "        if self.noise_dist is None:\n",
        "            noise_dist = torch.ones(self.n_vocab)\n",
        "        else:\n",
        "            noise_dist = self.noise_dist\n",
        "\n",
        "        if n_samples==0:\n",
        "            noise_vectors = None\n",
        "        else:\n",
        "          # torch.multinomial :\n",
        "          # Returns a tensor where each row contains (num_samples) **indices** sampled from\n",
        "          # multinomial probability distribution located in the corresponding row of tensor input.\n",
        "          noise_words = torch.multinomial(input       = noise_dist,           # input tensor containing probabilities\n",
        "                                          num_samples = batch_size*n_samples, # number of samples to draw\n",
        "                                          replacement = True)\n",
        "          noise_words = noise_words.to(device)\n",
        "\n",
        "          # use context matrix for embedding noise samples\n",
        "          noise_vectors = self.out_embed(noise_words).view(batch_size, n_samples, self.n_embed)\n",
        "\n",
        "        return noise_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Define Loss Class\n",
        "Modified loss function that only cares about :\n",
        "* current example\n",
        "* small subset of noise examples\n",
        "\n",
        "## Loss Formula\n",
        "$$\n",
        "- \\large \\log{\\sigma\\left(u_{w_O}\\hspace{0.001em}^\\top v_{w_I}\\right)} -\n",
        "\\sum_i^N \\mathbb{E}_{w_i \\sim P_n(w)}\\log{\\sigma\\left(-u_{w_N}\\hspace{0.001em}^\\top v_{w_I}\\right)}\n",
        "$$\n",
        "\n",
        "* $u_{w_O}\\hspace{0.001em}$ : output embeddings\n",
        "* $v_{w_I}$ : input embeddings\n",
        "* $u_{w_N}$ : noise embeddings\n",
        "\n",
        "\n",
        "\n",
        "$$\\large \\log{\\sigma\\left(u_{w_O}\\hspace{0.001em}^\\top v_{w_I}\\right)}$$\n",
        "\n",
        "* Take the **log-sigmoid** of the **inner product of output word vector & input word vector**.\n",
        "  * Pushes *P(model will predict the correct word $w_O$)* towards 1.\n",
        "\n",
        "$$\\large \\sum_i^N \\mathbb{E}_{w_N \\sim P_n(w)}$$\n",
        "\n",
        "* Sum over words $w_N$ drawn from a noise distribution $w_N \\sim P_n(w)$.\n",
        "* For $P_n(w)$, we can use the unigram distribution $U(w)$ that takes into account the frequency that each word shows up in text corpus.\n",
        "* The authors found the best distribution to be $U(w)^{3/4}$.\n",
        "\n",
        "$$\\large \\log{\\sigma\\left(-u_{w_N}\\hspace{0.001em}^\\top v_{w_I}\\right)},$$\n",
        "\n",
        "* take the **log-sigmoid** of the ***negated*** **inner product of a noise vector with the input vector**.\n",
        "  * Pushes *P(model will predict the noise words)* towards 0."
      ],
      "metadata": {
        "id": "nngMKSEfWILZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7POGkLj6F2t"
      },
      "outputs": [],
      "source": [
        "class NegativeSamplingLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,\n",
        "              input_vectors,\n",
        "              output_vectors,\n",
        "              noise_vectors):\n",
        "\n",
        "    batch_size, embed_size = input_vectors.shape\n",
        "\n",
        "    input_vectors = input_vectors.view(batch_size, embed_size, 1)   # batch of column vectors\n",
        "    output_vectors = output_vectors.view(batch_size, 1, embed_size) # batch of row vectors\n",
        "\n",
        "    # log-sigmoid loss for correct pairs\n",
        "    out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log().squeeze()\n",
        "\n",
        "    # log-sigmoid loss for incorrect pairs\n",
        "    if noise_vectors is None:\n",
        "      noise_loss = 0.0\n",
        "    else:\n",
        "      noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
        "      noise_loss = noise_loss.squeeze().sum(1)  # sum the losses over the sample of noise vectors\n",
        "\n",
        "    return -(out_loss + noise_loss).mean()  # average batch loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Define Noise Distribution"
      ],
      "metadata": {
        "id": "CBrHQkXKRWbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As defined in the paper by Mikolov et all.\n",
        "freq = Counter(int_words)\n",
        "freq_ratio = {word:cnt/len(vocab_to_int) for word, cnt in freq.items()}\n",
        "freq_ratio = np.array(sorted(freq_ratio.values(), reverse=True))\n",
        "unigram_dist = freq_ratio / freq_ratio.sum()\n",
        "noise_dist = torch.from_numpy(unigram_dist**0.75 / np.sum(unigram_dist**0.75))"
      ],
      "metadata": {
        "id": "oFjo3w7CRX0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Define Model, Loss, & Optimizer"
      ],
      "metadata": {
        "id": "BSjoFCVPRZNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "embedding_dim = 20\n",
        "model = SkipGramNeg(len(vocab_to_int),\n",
        "                                 embedding_dim,\n",
        "                                 noise_dist )\n",
        "criterion = NegativeSamplingLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.003)"
      ],
      "metadata": {
        "id": "7Isaf0YfRbEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Train!"
      ],
      "metadata": {
        "id": "ObGLMUjpRcYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqi1QMG1L_is"
      },
      "outputs": [],
      "source": [
        "def train_skipgram(model,\n",
        "                   criterion,\n",
        "                   optimizer,\n",
        "                   int_words,\n",
        "                   n_negative_samples=5,\n",
        "                   batch_size=128,\n",
        "                   n_epochs=10,\n",
        "                   print_every=1500,\n",
        "                   ):\n",
        "  model.to(device)\n",
        "\n",
        "  step = 0\n",
        "  for epoch in range(n_epochs):\n",
        "    for inputs, targets in get_batches(int_words, batch_size=batch_size):\n",
        "      step += 1\n",
        "      inputs = torch.LongTensor(inputs).to(device)    # [b*n_context_words]\n",
        "      targets = torch.LongTensor(targets).to(device)  # [b*n_context_words]\n",
        "\n",
        "      embedded_input_words = model.forward_input(inputs)\n",
        "      embedded_target_words = model.forward_target(targets)\n",
        "      embedded_noise_words = model.forward_noise(batch_size=inputs.shape[0],\n",
        "                                                  n_samples=n_negative_samples)\n",
        "\n",
        "      loss = criterion(embedded_input_words, embedded_target_words, embedded_noise_words)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (step % print_every) == 0:\n",
        "        print(\"Epoch: {}/{}\".format((epoch+1), n_epochs))\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
        "        valid_idxs, similarities = cosine_similarity(model.in_embed)\n",
        "        _, closest_idxs = similarities.topk(6)\n",
        "        valid_idxs, closest_idxs = valid_idxs.to('cpu'), closest_idxs.to('cpu')\n",
        "\n",
        "        for ii, v_idx in enumerate(valid_idxs):\n",
        "          closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "          print(int_to_vocab[v_idx.item()] + \" | \"+ \", \".join(closest_words))\n",
        "\n",
        "        print(\"\\n...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_skipgram(model,\n",
        "               criterion,\n",
        "               optimizer,\n",
        "               int_words,\n",
        "               n_negative_samples=5)"
      ],
      "metadata": {
        "id": "DRiB4Oxgk2RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XOqynoO6F2u"
      },
      "source": [
        "# 13. Visualise the embeddings in 2D space\n",
        "\n",
        "# Question 2\n",
        "See if by plotting the embeddings in a 2D space you can see some clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg3gr1rR6F2u"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEZOcQ3q6F2u"
      },
      "outputs": [],
      "source": [
        "# getting embeddings from the embedding layer of our model, by name\n",
        "embeddings = model.in_embed.weight.to('cpu').data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjt_3YXP6F2u"
      },
      "outputs": [],
      "source": [
        "viz_words = 380\n",
        "tsne = TSNE()\n",
        "embed_tsne = tsne.fit_transform(embeddings[:viz_words, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSyfTw_86F2v"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 16))\n",
        "for idx in range(viz_words):\n",
        "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
        "    plt.annotate(int_to_vocab[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}